{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41502c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import matplotlib.dates as mdates\n",
    "import csv\n",
    "import re\n",
    "from scipy.stats import norm\n",
    "from templatematching import *\n",
    "from getanalisisfiles import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f6f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing fuctions\n",
    "base_path = \"/data/fast1/veronica-scratch-rainier-downsampling/drive1_ds\"\n",
    "start_date = \"2023-08-25_00\"\n",
    "end_date = \"2023-08-25_00\"\n",
    "\n",
    "# using the fuction get_file_list \n",
    "file_list = get_file_list(base_path,start_date,end_date)\n",
    "\n",
    "len(file_list)\n",
    "file_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3683dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of the templates\n",
    "\n",
    "template_list = glob.glob ('/data/data4/veronica-scratch-rainier/swarm_august2023/test-template-maker/test_4sec_templates/filtering/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd1647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory to save files CC\n",
    "base_directory_cc = '/data/data4/veronica-scratch-rainier/swarm_august2023/results_CC_TMA/'\n",
    "\n",
    "# Variable folder name\n",
    "template_size = 21  #20 #21 frankesitein, duration of the template (6 for test)\n",
    "folder_name = f'CC_{template_size}sec-templates'\n",
    "\n",
    "# Full path\n",
    "full_path = os.path.join(base_directory_cc, folder_name)\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "if not os.path.exists(full_path):\n",
    "    os.makedirs(full_path)\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the filter\n",
    "\n",
    "chan_min = 0 # from channel 0\n",
    "chan_max = 2500  #to channel 3000\n",
    "channel_number = chan_max -chan_min\n",
    "low_cut1 = 2\n",
    "hi_cut1 = 9.0\n",
    "#fs=attrs['MaximumFrequency']*2\n",
    "fs = 20\n",
    "samples_per_file = 60*fs\n",
    "b, a = butter(2, (low_cut1, hi_cut1), 'bp', fs=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd1af0",
   "metadata": {},
   "source": [
    "# Buiding outputfiles and correlations for each template on the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_files(file_list, template_list, chan_min, chan_max, channel_number, samples_per_file, b, a, full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab857960",
   "metadata": {},
   "source": [
    "# ANALYSIS OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculting the fuction\n",
    "output_dir = '/data/data4/veronica-scratch-rainier/swarm_august2023/results_CC_TMA/h5_files_timestamps'\n",
    "output_file_h5 = create_timestamps_h5(file_list, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70236322",
   "metadata": {},
   "outputs": [],
   "source": [
    "## timestamps to datetimeobject\n",
    "\n",
    "# opening the file that containg the timestamps\n",
    "with h5py.File(output_file_h5, 'r') as f:\n",
    "    timestamps_pt = np.array(f['timestamps'])\n",
    "\n",
    "# Define the Pacific Timezone\n",
    "pt_timezone = pytz.timezone('America/Los_Angeles')\n",
    "\n",
    "# Convert timestamps from microseconds to seconds\n",
    "timestamps_seconds = timestamps_pt / 1e6\n",
    "\n",
    "# Convert timestamps to datetime objects in Pacific Time\n",
    "datetime_objects_pt = [datetime.datetime.fromtimestamp(ts, pt_timezone) for ts in timestamps_seconds]\n",
    "\n",
    "# Define the UTC Timezone\n",
    "utc_timezone = pytz.timezone('UTC')\n",
    "\n",
    "# Convert datetime objects to UTC\n",
    "datetime_objects_utc = [dt_pt.astimezone(utc_timezone) for dt_pt in datetime_objects_pt]\n",
    "\n",
    "# Redifining times variables\n",
    "time_range = datetime_objects_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b36771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_path is going to give you the CC data set for this run, also calcultin MAD so we can define the thresold\n",
    "\n",
    "# Obtener una lista de todas las carpetas en el directorio base\n",
    "folders = [folder for folder in os.listdir(full_path) if os.path.isdir(os.path.join(full_path, folder))]\n",
    "\n",
    "# Inicializar una lista para almacenar los datos concatenados por cada carpeta\n",
    "concatenated_data_per_folder = []\n",
    "\n",
    "# Iterar sobre las carpetas y cargar los archivos .npy\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(full_path, folder)\n",
    "    npy_files = [np.load(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.endswith('.npy')]\n",
    "    concatenated_data_per_folder.append(np.concatenate(npy_files, axis=0))\n",
    "\n",
    "# calcuting mad for each folder and for defining the thresold later\n",
    "mads_per_folder = {}\n",
    "for folder, folder_data in zip(folders, concatenated_data_per_folder):\n",
    "    det_shelly,mad = detections(folder_data,mode='shelly')\n",
    "    thresh = np.round(np.abs(norm.ppf(1/fs/(60*60))))\n",
    "    #print(f\"MAD for folder {folder}: {mad}\")\n",
    "    print(f\"thresold for folder {folder}: {thresh}\")\n",
    "    det_ind = np.where(np.abs(det_shelly) > thresh)[0]\n",
    "    \n",
    "#average_mad = np.mean(list(mads_per_folder.values()))\n",
    "\n",
    "\n",
    "#print(f\"average mad {average_mad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d36dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Directorio base donde se encuentran las carpetas\n",
    "base_directory = '/data/data4/veronica-scratch-rainier/test_corr'\n",
    "\n",
    "# Obtener una lista de todas las carpetas en el directorio base\n",
    "folders = [folder for folder in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, folder))]\n",
    "\n",
    "# Inicializar una lista para almacenar los datos concatenados por cada carpeta\n",
    "concatenated_data_per_folder = []\n",
    "\n",
    "# Iterar sobre las carpetas y cargar los archivos .npy\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_directory, folder)\n",
    "    npy_files = [np.load(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.endswith('.npy')]\n",
    "    concatenated_data_per_folder.append(np.concatenate(npy_files, axis=0))\n",
    "\n",
    "# Crear el rango de fechas o tiempo con exactamente 20 objetos datetime por segundo\n",
    "# Asumiendo que ya tienes definido time_range adecuadamente\n",
    "\n",
    "# Graficar los datos para cada carpeta\n",
    "fig, axs = plt.subplots(len(folders), 1, figsize=(10, 5*len(folders)))\n",
    "\n",
    "for i, folder_data in enumerate(concatenated_data_per_folder):\n",
    "    axs[i].plot(time_range, folder_data, label=f'Folder {folders[i]}', color='blue', linestyle='-')\n",
    "    axs[i].set_title(f'Template {folders[i]}')\n",
    "    axs[i].set_xlabel('Time')\n",
    "    axs[i].set_ylabel('Correlation Value')\n",
    "    axs[i].legend()  # Add legend to each subplot\n",
    "    axs[i].set_ylim([0,0.5])  # Set y-axis limits from 0 to 0.5\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7efea5",
   "metadata": {},
   "source": [
    "# add thresold and detections stuff"
   ]
  },
  {
   "cell_type": "raw",
   "id": "599d5266",
   "metadata": {},
   "source": [
    "#the code took 9 hr for 15 templates, pretty efficient!\n",
    "#before we have 6 hour by template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52415f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define los umbrales\n",
    "thresholds = [0.5, 0.1, 0.05, 0.04, 0.035, 0.03]\n",
    "\n",
    "# Directorio donde se guardarán los archivos de texto\n",
    "output_directory = \"textfiles_results_thresholds\"\n",
    "\n",
    "# Itera sobre cada carpeta\n",
    "for folder, folder_data in zip(folders, concatenated_data_per_folder):\n",
    "    # Crear directorio si no existe\n",
    "    folder_output_directory = os.path.join(output_directory, folder)\n",
    "    if not os.path.exists(folder_output_directory):\n",
    "        os.makedirs(folder_output_directory)\n",
    "    \n",
    "    # Ruta del archivo de salida\n",
    "    output_file_path = os.path.join(folder_output_directory, f\"detections_results_{folder}.txt\")\n",
    "    \n",
    "    # Abre el archivo de salida en modo escritura\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        # Escribe los encabezados\n",
    "        file.write(\"Threshold\\tNumber of Detections\\tDetection Times (UTC)\\n\")\n",
    "\n",
    "        # Itera sobre cada umbral\n",
    "        for threshold in thresholds:\n",
    "            # Encuentra los índices donde los valores superan el umbral\n",
    "            indices_above_threshold = np.where(np.abs(folder_data) > threshold)[0]\n",
    "            diff_indices = np.diff(indices_above_threshold)\n",
    "            group_changes = np.where(diff_indices > 10)[0]\n",
    "            detection_groups = np.split(indices_above_threshold, group_changes + 1)\n",
    "\n",
    "            # Itera sobre cada grupo de detección\n",
    "            for group in detection_groups:\n",
    "                # Verifica si el grupo no está vacío\n",
    "                if len(group) > 0:\n",
    "                    # Toma solo la primera fecha en cada grupo\n",
    "                    first_detection_time_utc = time_range[group[0]].strftime('%Y-%m-%d_%H.%M.%S')\n",
    "                    #first_detection_time_utc = datetime.datetime.utcfromtimestamp(time_range[group[0]].timestamp()).strftime('%Y-%m-%d_%H.%M.%S')\n",
    "                    \n",
    "                    # Escribe los datos en una fila separados por tabulaciones\n",
    "                    file.write(f\"{threshold}\\t{len(detection_groups)}\\t{first_detection_time_utc}\\n\")\n",
    "                else:\n",
    "                    print(\"Grupo vacío encontrado para el umbral:\", threshold)\n",
    "\n",
    "# Mensaje de confirmación\n",
    "print(f\"Los resultados se han guardado en {output_directory}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Obspy+LibComtCat)",
   "language": "python",
   "name": "python-obspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
