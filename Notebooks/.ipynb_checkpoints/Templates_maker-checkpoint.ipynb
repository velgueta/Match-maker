{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import pytz\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a7f65c",
   "metadata": {},
   "source": [
    "Este archivo crea templates apartir de una base de datos importadas desde un archivo csv, luego busca esos datos en \n",
    "el DAS data y selecciona una ventana de tiempo apropiada (6 sec, 10 sec etc, y los guarda en cierto folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the templates made here, /data/data4/veronica-scratch-rainier/swarm_august2023/test-template-maker\n",
    "# vamos a extraer las fechas desde dates_test.csv, the format is id number of the event and hypocenter date, like this\n",
    "# 61953701,2023-08-27_10.10.23\n",
    "# vamos a hacer un template de 10 sec, cada archivo tiene 1200 puntos, por los que 200 puntos\n",
    "# vamos a solo usar 0 a 2500 channels que son los que considero buenos.\n",
    "# Aquí se encuentran los files a buscar file_list = glob.glob(\"/data/fast1/veronica-scratch-rainier-downsampling/drive1_ds/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eaf0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "chan_min = 0\n",
    "chan_max = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06642226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# Rutas de los directorios y archivo CSV\n",
    "csv_file_path = 'dates_test.csv'\n",
    "files_folder_path = '/data/fast1/veronica-scratch-rainier-downsampling/drive1_ds'\n",
    "output_folder_path = '/data/data4/veronica-scratch-rainier/swarm_august2023/test-template-maker/test_4sec_templates/raw'\n",
    "output_folder_path_filter = '/data/data4/veronica-scratch-rainier/swarm_august2023/test-template-maker/test_4sec_templates/filtering'\n",
    "\n",
    "# Lista para almacenar las fechas del archivo CSV\n",
    "original_dates = []\n",
    "\n",
    "# Leer las fechas del archivo CSV\n",
    "with open(csv_file_path, 'r') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for row in csv_reader:\n",
    "        date_with_seconds = row[1]\n",
    "        original_dates.append(date_with_seconds)\n",
    "        \n",
    "\n",
    "\n",
    "# Expresión regular para buscar fechas en el formato correcto (incluyendo hora y minutos)\n",
    "date_pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2}_\\d{2}\\.\\d{2}\\.\\d{2})')\n",
    "# Lista para almacenar los nombres de los archivos encontrados\n",
    "found_files = []\n",
    "\n",
    "# Iterar sobre las fechas originales y buscar archivos correspondientes con la fecha específica\n",
    "for date_to_search in original_dates:\n",
    "    match = date_pattern.match(date_to_search)\n",
    "    if match:\n",
    "        formatted_date = match.group(1)\n",
    "        currenttime_datetime = datetime.strptime(formatted_date, '%Y-%m-%d_%H.%M.%S')\n",
    "        #print(currenttime_datetime.second)\n",
    "        \n",
    "        #defining the second to do teh exception\n",
    "        if 56 <= currenttime_datetime.second <= 59:\n",
    "            next_minute = currenttime_datetime + timedelta(minutes=1)\n",
    "            formatted_date_2 = next_minute.strftime('%Y-%m-%d_%H.%M.00')\n",
    "            #print(formatted_date_2)\n",
    "        else:\n",
    "            formatted_date_2 = currenttime_datetime.strftime('%Y-%m-%d_%H.%M.00')\n",
    "            #print(formatted_date_2)\n",
    "    \n",
    "        #so, found_files contains all the files that we need to process to create the templates.   (for 2023 swarm at least 47 files) \n",
    "        for file_name in os.listdir(files_folder_path):\n",
    "            if formatted_date_2 in file_name:\n",
    "                found_files.append(file_name)\n",
    "                #print(len(found_files))\n",
    "                #print(f\"Found a file with the searched date: {file_name}\")\n",
    "                \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar los archivos encontrados\n",
    "for file_name in found_files:\n",
    "    data_file_path = os.path.join(files_folder_path, file_name)\n",
    "    output_file_path = os.path.join(output_folder_path, file_name)\n",
    "    #print(output_file_path)\n",
    "    with h5py.File(data_file_path, 'r') as data_file:\n",
    "        # Obtener los datos y el tiempo\n",
    "        data = np.array(data_file['Acquisition/Raw[0]/RawData'][:, chan_min:chan_max])\n",
    "        time = np.array(data_file['Acquisition/Raw[0]/RawDataTime'])\n",
    "        #print(time)\n",
    "        \n",
    "        # Convertir las marcas de tiempo a objetos de datetime UTC\n",
    "        time_utc = [datetime.utcfromtimestamp(ts / 1000000) for ts in time]\n",
    "        \n",
    "        # Encontrar la marca de tiempo correspondiente en el tiempo UTC para la fecha de inicio y fin\n",
    "        date_to_search = original_dates[found_files.index(file_name)]\n",
    "        #print(date_to_search)\n",
    "        #print(len(date_to_search))\n",
    "        \n",
    "        start_date = datetime.strptime(date_to_search, \"%Y-%m-%d_%H.%M.%S\") + timedelta(seconds=2)\n",
    "        print(start_date)\n",
    "        end_date = start_date + timedelta(seconds=4)  # Añadir 4,8 etc segundos al inicio\n",
    "        \n",
    "        # Convertir las marcas de tiempo de inicio y fin a UTC\n",
    "        start_date_utc = start_date - (timedelta(hours=start_date.utcoffset().total_seconds() / 3600) if start_date.utcoffset() else timedelta(0))\n",
    "        end_date_utc = end_date - (timedelta(hours=end_date.utcoffset().total_seconds() / 3600) if end_date.utcoffset() else timedelta(0))\n",
    "        \n",
    "        # Encontrar los índices correspondientes en el tiempo para las fechas de inicio y fin en UTC\n",
    "        start_index = np.argmin(np.abs(np.array(time_utc) - start_date_utc))\n",
    "        end_index = np.argmin(np.abs(np.array(time_utc) - end_date_utc))\n",
    "\n",
    "        # Cortar los datos en el rango de tiempo deseado\n",
    "        data_cut = data[start_index:end_index]\n",
    "        time_cut = time[start_index:end_index]\n",
    "\n",
    "        # Guardar los datos cortados en un nuevo archivo HDF5\n",
    "        with h5py.File(output_file_path, 'w') as output_file:\n",
    "            output_file.create_dataset('Acquisition/Raw[0]/RawData', data=data_cut)\n",
    "            output_file.create_dataset('Acquisition/Raw[0]/RawDataTime', data=time_cut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar los archivos encontrados\n",
    "for file_name in found_files:\n",
    "    data_file_path = os.path.join(output_folder_path, file_name)  # Usar la carpeta de salida\n",
    "    with h5py.File(data_file_path, 'r') as data_file:\n",
    "        # Obtener los datos y el tiempo cortados\n",
    "        data_cut = np.array(data_file['Acquisition/Raw[0]/RawData'])\n",
    "        time_cut = np.array(data_file['Acquisition/Raw[0]/RawDataTime'])\n",
    "\n",
    "        # Convertir las marcas de tiempo a objetos de datetime UTC\n",
    "        time_utc = [datetime.utcfromtimestamp(ts / 1000000) for ts in time_cut]\n",
    "\n",
    "        # Configurar la figura y los ejes\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        # Graficar los datos\n",
    "        plt.imshow(data_cut.T, cmap='seismic', aspect='auto', vmin=-0.05, vmax=0.05,\n",
    "                   extent=[mdates.date2num(time_utc[0]), mdates.date2num(time_utc[-1]), data_cut.shape[1], 0])\n",
    "\n",
    "        # Configurar etiquetas y formato de fecha en el eje x\n",
    "        plt.xlabel(\"Tiempo UTC\", fontsize=25)\n",
    "        plt.ylabel(\"Distancia óptica (km)\", fontsize=25)\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        ax.xaxis_date()\n",
    "\n",
    "        # Mostrar la figura\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78dab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering these files\n",
    "\n",
    "# Define constants for filtering\n",
    "low_cut1 = 2\n",
    "hi_cut1 = 9\n",
    "fs = 20\n",
    "\n",
    "# Iterate over files in the output folder\n",
    "for file_name in os.listdir(output_folder_path):\n",
    "    if file_name.endswith('.h5'):  # Process only HDF5 files\n",
    "        # Construct paths\n",
    "        data_file_path = os.path.join(output_folder_path, file_name)\n",
    "        output_file_path_filtering = os.path.join(output_folder_path_filter, file_name)\n",
    "        \n",
    "        # Open the HDF5 file\n",
    "        with h5py.File(data_file_path, 'r') as data_file:\n",
    "            # Extract data and time\n",
    "            this_data = np.array(data_file['Acquisition/Raw[0]/RawData'][:, :])\n",
    "            #len(this_data)# Assuming you want all channels\n",
    "            this_time = np.array(data_file['Acquisition/Raw[0]/RawDataTime'])\n",
    "        \n",
    "        # Apply Butterworth bandpass filter\n",
    "        \n",
    "            b,a = butter(2,(low_cut1,hi_cut1),'bp',fs=fs)\n",
    "            data_filt = filtfilt(b,a,this_data,axis=0)\n",
    "        \n",
    "        # Save the filtered data into a new HDF5 file\n",
    "        with h5py.File(output_file_path_filtering, 'w') as output_file:\n",
    "            output_file.create_dataset('Acquisition/Raw[0]/RawData', data=data_filt)\n",
    "            output_file.create_dataset('Acquisition/Raw[0]/RawDataTime', data=this_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d8bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(output_folder_path_filter):\n",
    "    if file_name.endswith('.h5'):  # Procesar solo archivos HDF5\n",
    "        # Construir la ruta al archivo HDF5 filtrado\n",
    "        filtered_file_path = os.path.join(output_folder_path_filter, file_name)\n",
    "        \n",
    "        # Abrir el archivo HDF5 filtrado\n",
    "        with h5py.File(filtered_file_path, 'r') as filtered_file:\n",
    "            # Leer los datos filtrados y el tiempo desde el archivo HDF5\n",
    "            filtered_data = np.array(filtered_file['Acquisition/Raw[0]/RawData'])\n",
    "            time_data = np.array(filtered_file['Acquisition/Raw[0]/RawDataTime'])\n",
    "        \n",
    "        # Mostrar los datos filtrados utilizando imshow\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(filtered_data.T, cmap='seismic', aspect='auto', vmin=-0.05, vmax=0.05,\n",
    "                   extent=(time_data[0], time_data[-1], 0, filtered_data.shape[1]))\n",
    "        plt.colorbar(label='Amplitude')\n",
    "        plt.title(f'Filtered Data: {file_name}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Channel')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85c9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Obspy)",
   "language": "python",
   "name": "obspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
